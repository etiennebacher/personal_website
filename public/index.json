[{"authors":null,"categories":["R"],"content":"{assemblr} is an R package and addin whose aim is to make it easier to build regression tables. More specifically, it provides an interactive environment to create regression tables with the {stargazer} package. You can check the development of this package here.\nWhy {assemblr}?\nDuring my academic works with R, I used a lot the {stargazer} and {texreg} packages to produce regression tables. These are incredibly helpful, and provide a lot of options to customize the LaTeX format, which I primarily use. However, it is easy to be lost among all of these options, and it\u0026rsquo;s not really possible to know exactly what the table will look like.\nTherefore, I thought it would be a good idea to create an RStudio addin that takes the form of a Shiny app, and that allows to design regression tables with live preview. With this, the users could actually play with the multiple options, and easily check if they like them or not. All of these options would then be saved and the code to build the corresponding table would be provided when the user is done.\nBesides being useful for the user, this project is also useful to me! Indeed, it has become the way to learn how to make an R package, how to make an RStudio addin (which is not hard once you have a package), and how to use the {golem} package for Shiny apps.\n","date":1600905600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600905600,"objectID":"0f9ec72c69a0c46e5ea9e48b3337e733","permalink":"/project/assemblr/","publishdate":"2020-09-24T00:00:00Z","relpermalink":"/project/assemblr/","section":"project","summary":"An R package and addin whose aim is to make it easier to build regression tables","tags":["R"],"title":"assemblr","type":"project"},{"authors":null,"categories":null,"content":"  Why bookdown? LaTeX packages and commands Titlepage, acknowledgements and abstract Include LaTeX files in YAML Summary   I finished my Master’s thesis very recently, and I wrote it with R Markdown, and more precisely with the bookdown package. It was really comfortable to do absolutely everything with R: data treatment, use of econometric methods, redaction with chunk of codes, and even the slides for the presentation! However, I have also spent a non-negligible part of my time trying to have a correct layout, essentially for the first pages. I found that some things were not as easy to do as they should be. This post contains some solutions to these problems.\nWhy bookdown? A small preamble before starting to list these problems and solutions: why did I use bookdown and not rmarkdown? bookdown has a few advantages that are very important when writing a Master’s thesis (or an academic paper in general), such as cross-references between sections, figures, tables, etc. See the bookdown book for all the details.\nWhile it is possible to create a bookdown project with RStudio, I “manually” made my own, because I have the impression there are a lot of files created automatically by RStudio that would just confuse myself. Therefore, I had a file containing the YAML and the chunks necessary to load all the packages needed and to run the child documents. Child documents are .Rmd files that contain only some Markdown text and code chunks (no YAML). They make it much easier to write a thesis since it is possible to divide it in several pieces (introduction, literature review, method, etc.).\nIn addition to Global.Rmd (which contains YAML and setup chunks), I used two .tex files: preamble.tex is where I put all the LaTeX commands and packages I used, and titlepage.tex to make my custom titlepage, acknowledgments and abstract before the table of contents.\n LaTeX packages and commands In preamble.tex, I put all the LaTeX commands, many of them being \\usepackage. For example, the R package kableExtra provides a list of LaTeX packages required to be able to customize the tables (see here).\nHere’s a small list of the commands I used for my thesis.\n \\renewcommand{\\baselinestretch}{1.3} to change the space between lines;\n \\pagenumbering{gobble} to remove page numbering for the first pages, that contain the title, the table of content (TOC), the lists of figures and tables (LOF and LOT) and some blank pages. I used \\pagenumbering{arabic} after the YAML to start the page numbering at the right place.\n \\usepackage{caption}; \\captionsetup[table]{name=Tableau}; \\captionsetup[figure]{name=Figure}. These three commands (to put on three separate lines) are here to change the name of tables and figures. If you’re writing in English, you probably won’t need them, but they were necessary to write in French.\n the following lines create a new command to create a blank page after the titlepage. Strangely, \\pagebreak or \\newpage didn’t work inside the titlepage and I had to find an alternative:\n    Command to create a blank page   \\usepackage{afterpage} \\newcommand\\blankpage{% \\null \\thispagestyle{empty}% \\addtocounter{page}{-1}% \\newpage}   Titlepage, acknowledgements and abstract Concerning these three components, I put them in another file named titlepage.tex. This is the layout I wanted:\n a titlepage with some logos and some information on my thesis and my university;\n a blank page;\n acknowledgements on a new page;\n abstract on a new page;\n TOC, LOF and LOT on a new page.\n  To do so, I started the titlepage with \\begin{titlepage} and customized it as I wanted. But before putting \\end{titlepage}, I placed \\afterpage{\\blankpage}, which is the command we define in preamble.tex. With this, I had a titlepage and a blank page.\nThe next step was to create two pages containing the acknowledgements and the abstract This was easily done in LaTeX, and this time I could use \\pagebreak at the end of the acknowledgements to create a new page for the abstract. I also put another \\pagebreak to finish titlepage.tex, so that TOC, LOF and LOT (created in the YAML) could start on a new page.\n Include LaTeX files in YAML As explained, I had two .tex files to run when compiling the R Markdown file:\n preamble.tex is a list of commands that should be placed before \\begin{document} when this .Rmd file will be converted to .tex. Therefore, I used in_header in the YAML to compile it.\n titlepage.tex contains some elements that should be in the final PDF document. Since this should appear first (before the rest of the .Rmd document), I used before_body in the YAML.\n   Summary Here are examples of the three files: Global.Rmd, preamble.tex and titlepage.tex.\n  Global.Rmd   --- output: bookdown::pdf_book: includes: in_header: preamble.tex before_body: titlepage.tex keep_tex: true toc: yes toc_depth: 3 indent: true link-citations: yes lot: true lof: true --- \u0026lt;!-- Start the redaction on a new page --\u0026gt; \\newpage \u0026lt;!-- Start page numbering where the redaction starts --\u0026gt; \\pagenumbering{arabic} ```{r globaloptions, include=FALSE} # Include here chunk options ``` ```{r packages} # Load here the packages ``` \u0026lt;!-- Call the child documents --\u0026gt; ```{r body, child = c(\u0026#39;01-Intro.Rmd\u0026#39;, \u0026#39;02-Literature.Rmd\u0026#39;, \u0026#39;03-Data-and-method.Rmd\u0026#39;, \u0026#39;04-Results.Rmd\u0026#39;, \u0026#39;05-Discussion.Rmd\u0026#39;, \u0026#39;06-Conclusion.Rmd\u0026#39;)} ``` \u0026lt;!-- Placement of bibliography --\u0026gt; # References {-} \u0026lt;div id=\u0026quot;refs\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- Place the appendix after the bibliography --\u0026gt; ```{r appendix, child = c(\u0026#39;07--Appendix.Rmd\u0026#39;)} ```    preamble.tex   % Line spacing \\renewcommand{\\baselinestretch}{1.3} % Page number and chapter at the top of the page \\pagestyle{headings} % Important packages \\usepackage[utf8]{inputenc} \\usepackage[T1]{fontenc} \\usepackage[dvipsnames]{xcolor} \\usepackage{hyperref} \\usepackage{dcolumn} \\usepackage{booktabs} \\usepackage{longtable} % Figure and table names \\usepackage{caption} \\captionsetup[table]{name=Tableau} \\captionsetup[figure]{name=Figure} % Packages for kableExtra \\usepackage{array} \\usepackage{multirow} \\usepackage{wrapfig} \\usepackage{colortbl} \\usepackage{pdflscape} \\usepackage{float} \\usepackage{tabu} \\usepackage{threeparttable} \\usepackage{threeparttablex} \\usepackage[normalem]{ulem} \\usepackage{makecell} % Remove page numbering before start of redaction \\pagenumbering{gobble} % Command to make a blank page \\usepackage{afterpage} \\newcommand\\blankpage{% \\null \\thispagestyle{empty}% \\addtocounter{page}{-1}% \\newpage}    titlepage.tex   \\begin{titlepage} \\centering Title of my thesis \\afterpage{\\blankpage} \\end{titlepage} \\section*{Acknowledgements} Thanks everyone \\pagebreak \\begin{center} \\textbf{Abstract} \\end{center} Bla bla bla... \\pagebreak  Hope this helps!\n ","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594857600,"objectID":"c74e15f4c9889184de9a620058cd8a17","permalink":"/post/tips-and-tricks-r-markdown/tips-and-tricks-r-markdown/","publishdate":"2020-07-16T00:00:00Z","relpermalink":"/post/tips-and-tricks-r-markdown/tips-and-tricks-r-markdown/","section":"post","summary":"I wrote my Master's thesis with bookdown. This post contains some tips to modify the layout and other stuff.","tags":["R","R Markdown"],"title":"Writing a Master's thesis with R Markdown and Bookdown","type":"post"},{"authors":null,"categories":[],"content":"  Read the error message Search on StackOverflow and RStudio Community Search on Github Post my question online - Part 1 Post my question online - Part 2 Additional resources   As Jenny Bryan said, one of the first things people do when there is a problem with the code is run it a second time. But in 95% of the cases (in my small programming experience), this does not solve the problem, and I realized I developed a small pattern of reactions when I am in this situation.\nRead the error message This may seem obvious since this is the first thing we see when there is an error. However, some messages (like those in the tidyverse packages) are really helpful and are enough to solve the problem.\nAs you spend time programming, some error messages become quite familiar over time. You don’t necessarily need to fully understand the message, just remember how you solved the error when you saw this. But this does not help if this is the first time you see the message.\n Search on StackOverflow and RStudio Community If the error message was not helpful, I quickly go to step 2: search online (which is almost always equivalent to “search on StackOverflow and RStudio Community”). Those are the two places where you have the most odds of finding an answer to your problem. If your problem concerns mainstream packages (once again, such as the tidyverse ones), then there will always be at least one person who had a similar problem for which a solution was given.\n Search on Github If no answer was available on these two websites, I usually go a step further and search about it on GitHub, especially if the problem comes from an unknown and/or new package. Indeed, the source code of a lot of R packages is available on GitHub, as well as the brand-new versions (not on CRAN yet). It is also the place where people make feedback on some issues or help develop the package.\nIt happens that somebody reported a similar issue and that the package maintainer answered. If not, well, it is always useful to see the situations in which people use the package, or to learn new functions of this package.\n Post my question online - Part 1 I have an error, I don’t understand the error message and there are no answers online. What can I do now?\nYou can post your question on one of the websites I mentioned. My order of preference is:\n StackOverflow: in general, more people see your message and therefore more people might answer your question.\n RStudio Community: more “specialized” and some mainstream packages maintainers are there. Also useful when the question is about RStudio IDE (not to be confused with the R language) since they developed it.\n GitHub: clearly the problem comes from an error specific to the package and I couldn’t find an answer online. Most of the time, there is no need to create new issues.\n  However: posting a question online implies that you need to create a reproducible example. What is a reproducible example?\nSuppose that you are working on your data and have a problem. You may want to copy and paste your code online. It’s quick and easy. But try to imagine you’re someone on StackOverflow that sees your code for the first time. This person needs to run it to understand what your code does and what the problem is. But that’s impossible, because you load CSV data that is only available for you, or because you forgot to mention the packages you’re using. Therefore, no one can run your code and the odds of someone solving your problem plummet.\nIf you post online, your post MUST contain:\n A description of what you’re trying to do and of your problem in plain text.\n Some code that contains:\n the library() calls needed to run every function you use (but no need to put packages that you never use in your example)\n a code that can be copied and pasted in a new R session and that ends up in the same situation as you’re in. That means that the data you use must be reproducible.\n the expected output, if possible. If you can easily show the output you want, do it. It will be easier to help you if you show what you want. In some cases (e.g Shiny apps), it is not always possible or easy to provide this, so it is not a 100% necessary.\n   Making a reproducible example takes time but is incredibly helpful. Open a new tab in RStudio, try to simplify your situation as much as possible and to make it reproducible by using data available for everyone. For example, some datasets are automatically in R, such as mtcars or iris. Don’t forget to mention the packages you use in library(). Once you think you have finished (you show what packages you use, you keep your example as small as possible and you show the expected output), restart the session (ctrl + shift + F10) and see if it runs and if it reproduces the same error. If it doesn’t, it means your example is not reproducible and that you have to improve it.\nI would say that I solve the problem myself by making a reproducible example in 70% of the cases, so taking the time to make one is worth it!\n Post my question online - Part 2 However, if you didn’t solve your problem with this (and if your example is reproducible), you can post it on StackOverflow or RStudio Community. Don’t forget to explain your situation and your code, don’t paste it without any details!\nHopefully, you’ll have an answer.\n Additional resources Here are two pages with details about making a reproducible example:\n https://stackoverflow.com/help/minimal-reproducible-example\n https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example\n   ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"83c07eb78cf803adc861dfb7b47b177d","permalink":"/post/code-doesnt-work/what-to-do-when-your-code-does-not-work/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/post/code-doesnt-work/what-to-do-when-your-code-does-not-work/","section":"post","summary":"This is the list of actions I make when I have an error in R.","tags":["R"],"title":"What to do when your code doesn't work?","type":"post"},{"authors":null,"categories":[],"content":" One of the greatest things about R is the possibility to build websites quite easily with R Shiny. I started to create apps with Shiny almost immediately after having discovered it. This was in May last year and two months later I thought it would be a great idea to build an app to treat more easily World Bank data. Indeed, in my field, World Development Indicators (WDI) are often used and I thought it would be useful to have a graphical interface where we can import and treat these indicators.\nSo in July last year I started to work on this. Besides building something useful, I considered this as a good opportunity to practice with R Shiny. I worked on that irregularly during the rest of the year. Sometimes I considerably improved my app in a week and sometimes I spent two months not thinking about it.\nIn January, I was quite stuck: my app required to generate pieces of UI (User Interface) on the fly and I didn’t know how to do that. But when I saw the announcement for the second edition of the Shiny Contest, I convinced myself to give it a try and worked a lot on my app, especially since I finally understood how to use modules. Therefore, after a few weeks, I could finally deploy my app and participate to the contest. Given the incredible apps of other participants (just look at the “Shiny Contest” tag on RStudio Community), I know that there is not a chance that I win something but nonetheless I am very proud of having the possibility to show what I can do.\n“That’s very good”, you may say, “but what does your app do?”. Well if you are familiar with the WDIs, you know that each indicator has an ID (like “NV.AGR.TOTL.ZS”). Using this ID in my app, you can import the dataset related, choose the type of data you want (cross-country, time series, panel data), the country/countries and year(s) you want and compute the logarithm, the squared value and the lagged value of the variable. You may also generate a plot that you can download for this dataset. You can import and manipulate as many datasets as you desire and when you are done, you can merge them in a final dataset that is also downloadable. Finally, since reproducibility is a big aspect in science, all the manipulations you did are translated into R code so that you can copy and paste this code in a fresh R session and it will reproduce everything you have done. This was made possible thanks the great (but still experimental) shinymeta package1.\nYou can try the app here, but if it has been removed by the time you go checking it, you may find the source code for the whole app on GitHub.\n Luckily, I have discovered this package a month before I launched my app, in a rstudio::conf 2020 presentation by Carson Sievert↩︎\n   ","date":1586304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586304000,"objectID":"347cdae16ab905f61265da9fc65720e8","permalink":"/post/my-shiny-app/my-shiny-app/","publishdate":"2020-04-08T00:00:00Z","relpermalink":"/post/my-shiny-app/my-shiny-app/","section":"post","summary":"A presentation of the application I submitted to the Shiny Contest 2nd edition.","tags":["R"],"title":"My application for the Shiny Contest (2020)","type":"post"},{"authors":null,"categories":[],"content":"  “Ctrl+Shift+Enter”: run the whole script “Ctrl+Shift+F10”: restart R session “Ctrl+Shift+K”: knit Markdown documents “Ctrl+Alt+B”: run the script from the beginning to where I am “Ctrl+Shift+A”: good alignment “Ctrl+Shift+R”: new section label “Ctrl+Shift+N”: new file “Ctrl+Shift+C”: comment and un-comment lines of code   Currently working on my master’s thesis, I spend almost half on my day on R (the other half being spent reading articles). I have learnt a few very useful shortcuts by reading blog posts or free R books here and there and I have decided to make a small list of those I use most.\n“Ctrl+Shift+Enter”: run the whole script This combination will run all of your script, wherever the mouse is in the script. This considerably saves some time and is much more convenient than having to drag the mouse up to the “Run” button.\n “Ctrl+Shift+F10”: restart R session Almost all your work will have to be done again one day, either by you or by somebody else. That day, you will regret not having saved all the packages you needed in your R script. How is that possible? Well, it comes from the fact that I (and presumably other people too) load some packages and their dependencies in the same session because we test some packages, or because we are trying to solve a StackOverflow problem during a break, etc. Therefore, when you were writing it, some of your code was running only thanks to some packages you didn’t keep in your script.\nTo prevent this to happen again, you can run “Ctrl+Shift+F10” sometimes: it restarts the R session (but does not close RStudio) and allows to see quickly if your code can run all by itself. When I have finished writing a chunk of code, I always do “Ctrl+Shift+F10” and “Ctrl+Shift+Enter” to make sure that my code can run again in three months or more.\n “Ctrl+Shift+K”: knit Markdown documents I do not use this everywhere but only in Markdown documents: it knits the document. As “Ctrl+Shift+Enter” replaces the “Run” button, “Ctrl+Shift+K” replaces the “Knit” button.\n “Ctrl+Alt+B”: run the script from the beginning to where I am This is similar to “Ctrl+Shift+Enter” but it runs the script only until your mouse.\n “Ctrl+Shift+A”: good alignment Indentation is quite important to have a code that is readable, especially when you begin to write more than 10 lines of code. Select your code (or just a piece of it) and do this combination to apply indentation rules automatically.\n “Ctrl+Shift+R”: new section label This creates a new section in your code, with the title you choose. Quite convenient to keep a readable code.\n “Ctrl+Shift+N”: new file If you want to try a chunk of code quickly, you can run this combination to open a new file in RStudio.\n “Ctrl+Shift+C”: comment and un-comment lines of code To me, this is one of the most convenient shortcut. It simply allows to comment (and un-comment) at once all the lines selected.\n\nThe complete list of shortcuts is available in “Tools -\u0026gt; Keyboard Shortcuts Help” in RStudio. Other useful tools:\n snippets addins RStudio tips (on Twitter)   ","date":1586131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586131200,"objectID":"76b68cb3cb3fb8d75ea2402a96c288fc","permalink":"/post/my-favorite-shortcuts/my-favorite-shortcuts-in-rstudio/","publishdate":"2020-04-06T00:00:00Z","relpermalink":"/post/my-favorite-shortcuts/my-favorite-shortcuts-in-rstudio/","section":"post","summary":"Did you know that RStudio contains a lot of shortcuts to write code faster? Here are my favorites.","tags":["R"],"title":"My favorite shortcuts in RStudio","type":"post"},{"authors":null,"categories":null,"content":"  Files used and organization of the project Import data Merge dataframes Clean the data Descriptive Statistics Plots    Note:  In this and future articles, you will see some arrows below R code. If you click on it, it will display the Stata code equivalent to the R code displayed. However, since those are two different softwares, they are not completely equivalent and some of the Stata code may not fully correspond to the R code. Consider it more like a reference point not to be lost rather than like an exact equivalent. \nIn this post, you will see how to import and treat data, make descriptive statistics and a few plots. I will also show you a personal method to organize one’s work.\nFiles used and organization of the project First of all, you need to create a project. In RStudio, you can do “File”, “New Project” and then choose the location of the project and its name. In the folder that contains the project, I have several sub-folders: Figures, Bases_Used, Bases_Created. To be able to save or use files in these particular sub-folders, I use the package here. The command here() shows the path to your project and you just need to complete the path to access to your datasets or other files.\n# if you\u0026#39;ve never installed this package before, do: # install.packages(\u0026quot;here\u0026quot;) library(here) Why is this package important? Your code must be reproducible, either for your current collaborators to work efficiently with you or for other people to check your code and to use it in the future. Using paths that work only for your computer (like “/home/Mr X/somefolder/somesubfolder/Project”) makes it longer and more annoying to use your code since it requires to manually change paths in order to import data or other files. The package here makes it much easier to reproduce your code since it automatically detects the path to access to your data. You only need to keep the same structure between R files and datasets. You will see in the next part how to use it.\n Import data We will use data contained in Excel (.xlsx) and text (.txt) files. You can find these files (and the full R script corresponding to this post) here. To import Excel data, we will need the readxl package.\nlibrary(readxl) We use the read_excel function of this package to import excel files and the function read.table (in base R) to import the data:\nbase1 \u0026lt;- read_excel(here(\u0026quot;Bases_Used/Base_Excel.xlsx\u0026quot;), sheet = \u0026quot;Base1\u0026quot;) base2 \u0026lt;- read_excel(here(\u0026quot;Bases_Used/Base_Excel.xlsx\u0026quot;), sheet = \u0026quot;Base2\u0026quot;) base3 \u0026lt;- read_excel(here(\u0026quot;Bases_Used/Base_Excel.xlsx\u0026quot;), sheet = \u0026quot;Base3\u0026quot;) base4 \u0026lt;- read.table(here(\u0026quot;Bases_Used/Base_Text.txt\u0026quot;), header = TRUE)   Stata   cd \u0026quot;/path/to/Bases_Used\u0026quot; import excel using Base_Excel, sheet(\u0026quot;Base1\u0026quot;) firstrow  As you can see, if your project is in a folder and if you stored you datasets in the Bases_Used subfolder, this code will work automatically since here detects the path. Now, we have stored the four datasets in four objects called data.frames. To me, this simple thing is an advantage on Stata where storing multiple datasets in the same time is not intuitive at all.\n Merge dataframes We want to have a unique dataset to make descriptive statistics and econometrics (we will just do descriptive statistics in this post). Therefore, we will merge these datasets together, first by using the dplyr package. This package is one of the references for data manipulation. It is extremely useful and much more easy to use than base R. You may find a cheatsheet (i.e. a recap of the functions) for this package here, along with cheatsheets of many other great packages.\nFirst, we want to regroup base1 and base2. To do so, we just need to put one under the other and to “stick” them together with bind_rows and we observe the result:\nlibrary(dplyr) base_created \u0026lt;- bind_rows(base1, base2) base_created ## # A tibble: 23 x 6 ## hhid indidy1 surname name gender wage ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 BROWN Robert 1 2000 ## 2 1 2 JONES Michael 1 2100 ## 3 1 3 MILLER William 1 2300 ## 4 1 4 DAVIS David 1 1800 ## 5 2 1 RODRIGUEZ Mary 2 3600 ## 6 2 2 MARTINEZ Patricia 2 3500 ## 7 2 3 WILSON Linda 2 1900 ## 8 2 4 ANDERSON Richard 1 1900 ## 9 3 1 THOMAS Charles 1 1800 ## 10 3 2 TAYLOR Barbara 2 1890 ## # … with 13 more rows   Stata   preserve *** Open base #2 and bind the rows clear all import excel using Base_Excel, sheet(\u0026quot;Base2\u0026quot;) firstrow tempfile base2 save `base2\u0026#39; restore append using `base2\u0026#39;  As you can see, we obtain a dataframe with 6 columns (like each table separately) and 23 rows: 18 in the first table, 5 in the second table. Now, we merge this dataframe with base3. base_created and base3 only have one column in common (hhid) so we will need to specify that we want to merge these two bases by this column:\nbase_created \u0026lt;- left_join(base_created, base3, by = \u0026quot;hhid\u0026quot;) base_created ## # A tibble: 23 x 7 ## hhid indidy1 surname name gender wage location ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 1 BROWN Robert 1 2000 France ## 2 1 2 JONES Michael 1 2100 France ## 3 1 3 MILLER William 1 2300 France ## 4 1 4 DAVIS David 1 1800 France ## 5 2 1 RODRIGUEZ Mary 2 3600 England ## 6 2 2 MARTINEZ Patricia 2 3500 England ## 7 2 3 WILSON Linda 2 1900 England ## 8 2 4 ANDERSON Richard 1 1900 England ## 9 3 1 THOMAS Charles 1 1800 Spain ## 10 3 2 TAYLOR Barbara 2 1890 Spain ## # … with 13 more rows   Stata   preserve *** Open base #3 and merge clear all cd ..\\Bases_Used import excel using Base_Excel, sheet(\u0026quot;Base3\u0026quot;) firstrow tempfile base3 save `base3\u0026#39; restore merge m:1 hhid using `base3\u0026#39; drop _merge   left_join is a dplyr function saying that the first dataframe mentioned (here base_created) is the “most important” and that we will stick the second one (here base3) to it. If there are more rows in the first one than in the second one, then there will be some missing values but the number of rows will stay the same. If we knew that base3 had more rows than base_created, we would have used right_join.\nWe now want to merge base_created with base4. The problem is that there are no common columns so we will need to create one in each. Moreover, base_created contains data for the year 2019 and base4 for the year 2020. We will need to create columns to specify that too:\n# rename the second column of base_created and of base4 colnames(base_created)[2] \u0026lt;- \u0026quot;indid\u0026quot; colnames(base4)[2] \u0026lt;- \u0026quot;indid\u0026quot; # create the column \u0026quot;year\u0026quot;, that will take the value 2019 # for base_created and 2020 for base4 base_created$year \u0026lt;- 2019 base4$year \u0026lt;- 2020 From this point, we can merge these two dataframes:\nbase_created2 \u0026lt;- bind_rows(base_created, base4) base_created2 ## # A tibble: 46 x 8 ## hhid indid surname name gender wage location year ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 BROWN Robert 1 2000 France 2019 ## 2 1 2 JONES Michael 1 2100 France 2019 ## 3 1 3 MILLER William 1 2300 France 2019 ## 4 1 4 DAVIS David 1 1800 France 2019 ## 5 2 1 RODRIGUEZ Mary 2 3600 England 2019 ## 6 2 2 MARTINEZ Patricia 2 3500 England 2019 ## 7 2 3 WILSON Linda 2 1900 England 2019 ## 8 2 4 ANDERSON Richard 1 1900 England 2019 ## 9 3 1 THOMAS Charles 1 1800 Spain 2019 ## 10 3 2 TAYLOR Barbara 2 1890 Spain 2019 ## # … with 36 more rows   Stata    rename indidy1 indid gen year=2019 preserve * Open base #4 and merge clear all import delimited Base_Text.txt rename indidy2 indid gen year=2020 tempfile base4 save `base4\u0026#39; restore merge 1:1 hhid indid year using `base4\u0026#39; drop _merge  But we have many missing values for the new rows because base4 only contained three columns. We want to have a data frame arranged by household then by individual and finally by year. Using only dplyr functions, we can do:\nbase_created2 \u0026lt;- base_created2 %\u0026gt;% group_by(hhid, indid) %\u0026gt;% arrange(hhid, indid, year) %\u0026gt;% ungroup() base_created2 ## # A tibble: 46 x 8 ## hhid indid surname name gender wage location year ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 BROWN Robert 1 2000 France 2019 ## 2 1 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA 2136 \u0026lt;NA\u0026gt; 2020 ## 3 1 2 JONES Michael 1 2100 France 2019 ## 4 1 2 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA 2362 \u0026lt;NA\u0026gt; 2020 ## 5 1 3 MILLER William 1 2300 France 2019 ## 6 1 3 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA 2384 \u0026lt;NA\u0026gt; 2020 ## 7 1 4 DAVIS David 1 1800 France 2019 ## 8 1 4 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA 2090 \u0026lt;NA\u0026gt; 2020 ## 9 2 1 RODRIGUEZ Mary 2 3600 England 2019 ## 10 2 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA 3784 \u0026lt;NA\u0026gt; 2020 ## # … with 36 more rows Notice that there are some %\u0026gt;% between the lines: it is a pipe and its function is to connect lines of code between them so that we don’t have to write base_created2 every time. Now that our dataframe is arranged, we need to fill the missing values. Fortunately, these missing values do not change for an individual since they concern the gender, the location, the name and the surname. So basically, we can just take the value of the cell above (corresponding to year 2019) and replicate it in each cell (corresponding to year 2020):\nlibrary(tidyr) base_created2 \u0026lt;- base_created2 %\u0026gt;% fill(select_if(., ~ any(is.na(.))) %\u0026gt;% names(), .direction = \u0026#39;down\u0026#39;)   Stata   foreach x of varlist surname name gender location { bysort hhid indid: replace `x\u0026#39;=`x\u0026#39;[_n-1] if year==2020 }  Let me explain the code above:\n fill aims to fill cells select_if selects columns according to the condition defined any(is.na(.)) is a logical question asking if there are missing values (NA) . indicates that we want to apply the function to the whole dataframe names tells us what the names of the columns selected are .direction tells the direction in which the filling goes  So fill(select_if(., ~ any(is.na(.))) %\u0026gt;% names(), .direction = 'down') means that for the dataframe, we select each column which has some NA in it and we obtain their names. In these columns, the empty cells are filled by the value of the cell above (since the direction is “down”).\nFinally, we want the first three columns to be hhid, indid and year, and we create a ID column named hhind which is just the union of hhid and indid.\nbase_created2 \u0026lt;- base_created2 %\u0026gt;% select(hhid, indid, year, everything()) %\u0026gt;% unite(hhind, c(hhid, indid), sep = \u0026quot;\u0026quot;, remove = FALSE) base_created2 ## # A tibble: 46 x 9 ## hhind hhid indid year surname name gender wage location ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 11 1 1 2019 BROWN Robert 1 2000 France ## 2 11 1 1 2020 BROWN Robert 1 2136 France ## 3 12 1 2 2019 JONES Michael 1 2100 France ## 4 12 1 2 2020 JONES Michael 1 2362 France ## 5 13 1 3 2019 MILLER William 1 2300 France ## 6 13 1 3 2020 MILLER William 1 2384 France ## 7 14 1 4 2019 DAVIS David 1 1800 France ## 8 14 1 4 2020 DAVIS David 1 2090 France ## 9 21 2 1 2019 RODRIGUEZ Mary 2 3600 England ## 10 21 2 1 2020 RODRIGUEZ Mary 2 3784 England ## # … with 36 more rows   Stata   egen hhind=group(hhid indid) order hhind hhid indid year * sort hhid indid year   That’s it, we now have the complete dataframe.\n Clean the data There are still some things to do. First, we remark that there are some errors in the column location (England_error and Spain_error) so we correct it:\n# display the unique values of the column \u0026quot;location\u0026quot; unique(base_created2$location) ## [1] \u0026quot;France\u0026quot; \u0026quot;England\u0026quot; \u0026quot;Spain\u0026quot; \u0026quot;Italy\u0026quot; ## [5] \u0026quot;England_error\u0026quot; \u0026quot;Spain_error\u0026quot; # correct the errors base_created2[base_created2 == \u0026quot;England_error\u0026quot;] \u0026lt;- \u0026quot;England\u0026quot; base_created2[base_created2 == \u0026quot;Spain_error\u0026quot;] \u0026lt;- \u0026quot;Spain\u0026quot; unique(base_created2$location) ## [1] \u0026quot;France\u0026quot; \u0026quot;England\u0026quot; \u0026quot;Spain\u0026quot; \u0026quot;Italy\u0026quot;   Stata   replace localisation=\u0026quot;England\u0026quot; if localisation==\u0026quot;England_error\u0026quot; replace localisation=\u0026quot;Spain\u0026quot; if localisation==\u0026quot;Spain_error\u0026quot;  Basically, what we’ve done here is that we have selected every cell in the whole dataframe that had the value England_error (respectively Spain_error) and we replaced these cells by England (Spain). We also need to recode the column gender because binary variables have to take values of 0 or 1, not 1 or 2.\nbase_created2$gender \u0026lt;- recode(base_created2$gender, `2` = 0)   Stata   label define genderlab 1 \u0026quot;M\u0026quot; 2 \u0026quot;F\u0026quot; label values gender genderlab recode gender (2=0 \u0026quot;Female\u0026quot;) (1=1 \u0026quot;Male\u0026quot;), gen(gender2) drop gender rename gender2 gender  To have more details on the dataframe, we need to create some labels. To do so, we need the upData function in the Hmisc package.\nlibrary(Hmisc) var.labels \u0026lt;- c(hhind = \u0026quot;individual\u0026#39;s ID\u0026quot;, hhid = \u0026quot;household\u0026#39;s ID\u0026quot;, indid = \u0026quot;individual\u0026#39;s ID in the household\u0026quot;, year = \u0026quot;year\u0026quot;, surname = \u0026quot;surname\u0026quot;, name = \u0026quot;name\u0026quot;, gender = \u0026quot;1 if male, 0 if female\u0026quot;, wage = \u0026quot;wage\u0026quot;, location = \u0026quot;household\u0026#39;s location\u0026quot;) base_created2 \u0026lt;- upData(base_created2, labels = var.labels)   Stata   label variable hhind \u0026quot;individual\u0026#39;s ID\u0026quot; label variable indid \u0026quot;household\u0026#39;s ID\u0026quot; label variable year \u0026quot;year\u0026quot; label variable hhid \u0026quot;individual\u0026#39;s ID in the household\u0026quot; label variable surname \u0026quot;Surname\u0026quot; label variable name \u0026quot;Name\u0026quot; label variable gender \u0026quot;1 if male, 0 if female\u0026quot; label variable wage \u0026quot;wage\u0026quot; label variable location \u0026quot;household\u0026#39;s location\u0026quot;  We can see the result with:\ncontents(base_created2) ## ## Data frame:base_created2 46 observations and 9 variables Maximum # NAs:0 ## ## ## Labels Class Storage ## hhind individual\u0026#39;s ID character character ## hhid household\u0026#39;s ID integer integer ## indid individual\u0026#39;s ID in the household integer integer ## year year integer integer ## surname surname character character ## name name character character ## gender 1 if male, 0 if female integer integer ## wage wage integer integer ## location household\u0026#39;s location character character Now that our dataframe is clean and detailed, we can compute some descriptive statistics. But before doing it, we might want to save it:\nwrite.xlsx(base_created2, file = here(\u0026quot;Bases_Created/modified_base.xlsx\u0026quot;)   Stata   cd ..\\Bases_Created export excel using \u0026quot;modified_base.xls\u0026quot;, replace   Descriptive Statistics First of all, if we want to check the number of people per location or gender and per year, we use the table function:\ntable(base_created2$gender, base_created2$year) ## ## 2019 2020 ## 0 9 9 ## 1 14 14 table(base_created2$location, base_created2$year) ## ## 2019 2020 ## England 6 6 ## France 12 12 ## Italy 1 1 ## Spain 4 4   Stata   tab gender if year==2019 tab location if year==2019   To have more detailed statistics, you can use many functions. Here, we use the function describe from the Hmisc package\ndescribe(base_created2) ## base_created2 ## ## 9 Variables 46 Observations ## -------------------------------------------------------------------------------- ## hhind : individual\u0026#39;s ID ## n missing distinct ## 46 0 23 ## ## lowest : 11 12 13 14 21, highest: 71 72 81 82 83 ## -------------------------------------------------------------------------------- ## hhid : household\u0026#39;s ID ## n missing distinct Info Mean Gmd ## 46 0 8 0.975 4.217 2.783 ## ## lowest : 1 2 3 4 5, highest: 4 5 6 7 8 ## ## Value 1 2 3 4 5 6 7 8 ## Frequency 8 8 4 2 10 4 4 6 ## Proportion 0.174 0.174 0.087 0.043 0.217 0.087 0.087 0.130 ## -------------------------------------------------------------------------------- ## indid : individual\u0026#39;s ID in the household ## n missing distinct Info Mean Gmd ## 46 0 5 0.923 2.217 1.306 ## ## lowest : 1 2 3 4 5, highest: 1 2 3 4 5 ## ## Value 1 2 3 4 5 ## Frequency 16 14 8 6 2 ## Proportion 0.348 0.304 0.174 0.130 0.043 ## -------------------------------------------------------------------------------- ## year ## n missing distinct Info Mean Gmd ## 46 0 2 0.75 2020 0.5111 ## ## Value 2019 2020 ## Frequency 23 23 ## Proportion 0.5 0.5 ## -------------------------------------------------------------------------------- ## surname ## n missing distinct ## 46 0 23 ## ## lowest : ANDERSON BROWN DAVIS DOE JACKSON ## highest: THOMAS THOMPSON WHITE WILLIAMS WILSON ## -------------------------------------------------------------------------------- ## name ## n missing distinct ## 46 0 23 ## ## lowest : Barbara Charles Daniel David Donald ## highest: Richard Robert Susan Thomas William ## -------------------------------------------------------------------------------- ## gender : 1 if male, 0 if female ## n missing distinct Info Sum Mean Gmd ## 46 0 2 0.715 28 0.6087 0.487 ## ## -------------------------------------------------------------------------------- ## wage ## n missing distinct Info Mean Gmd .05 .10 ## 46 0 37 0.998 2059 477.4 1627 1692 ## .25 .50 .75 .90 .95 ## 1800 1901 2098 2373 3575 ## ## lowest : 1397 1600 1608 1683 1690, highest: 2384 3500 3600 3782 3784 ## -------------------------------------------------------------------------------- ## location : household\u0026#39;s location ## n missing distinct ## 46 0 4 ## ## Value England France Italy Spain ## Frequency 12 24 2 8 ## Proportion 0.261 0.522 0.043 0.174 ## --------------------------------------------------------------------------------   Stata   sum *, detail  but you can also try the function summary (automatically available in base R), stat.desc in pastecs, skim in skimr or even makeDataReport in dataMaid to have a complete PDF report summarizing your data. To summarize data under certain conditions (e.g. to have the average wage for each location), you can use dplyr:\n# you can change the argument in group_by() by gender for example base_created2 %\u0026gt;% group_by(location) %\u0026gt;% summarize_at(.vars = \u0026quot;wage\u0026quot;, .funs = \u0026quot;mean\u0026quot;) ## # A tibble: 4 x 2 ## location wage ## \u0026lt;labelled\u0026gt; \u0026lt;dbl\u0026gt; ## 1 England 2452. ## 2 France 1935. ## 3 Italy 1801 ## 4 Spain 1905.   Stata   tabstat wage if year==2019, stats(N mean sd min max p25 p50 p75) by(location) tabstat wage if year==2020, stats(N mean sd min max p25 p50 p75) by(location)   Plots Finally, we want to plot some data to include in our report or article (or anything else). ggplot2 is THE reference to make plots with R. The ggplot function does not create a graph but tells what is the data you are going to use and the aesthetics (aes). Here, we want to display the wages in a histogram and to distinguish them per year. Therefore, we want to fill the bars according to the year. To precise the type of graph we want, we add + geom_histogram() after ggplot. You may change the number of bins to have a more precise histogram.\nlibrary(ggplot2) hist1 \u0026lt;- ggplot(data = base_created2, mapping = aes(wage, fill = factor(year))) + geom_histogram(bins = 10) hist1   Stata   histogram wage if year==2019, saving(Hist1, replace) bin(10) freq title(\u0026quot;Year 2019\u0026quot;) ytitle(\u0026quot;Frequency\u0026quot;) histogram wage if year==2020, saving(Hist2, replace) bin(10) freq title(\u0026quot;Year 2020\u0026quot;) ytitle(\u0026quot;Frequency\u0026quot;)  If you prefer one histogram per year, you can use the facet_wrap() argument, as below.\nhist2 \u0026lt;- ggplot(data = base_created2, mapping = aes(wage, fill = factor(year))) + geom_histogram(bins = 10) + facet_wrap(vars(year)) hist2   Stata   graph combine Hist1.gph Hist2.gph, col(2) xsize(10) ysize(5) iscale(1.5) title(\u0026quot;{bf:Wage distribution per year}\u0026quot;)  Finally, you may want to export these graphs. To do so, we use ggsave (you can replace .pdf by .eps or .png if you want):\nggsave(here(\u0026quot;Figures/plot1.pdf\u0026quot;), plot = hist1)   Stata   graph export Histogram1.pdf, replace  That’s it! In this first post, you have seen how to import, clean and tidy datasets, and how to make some descriptive statistics and some plots. I hope this was helpful to you!\n ","date":1579651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579651200,"objectID":"e4c799caf38523ea395afead9d925c1a","permalink":"/post/first-contact/first-contact/","publishdate":"2020-01-22T00:00:00Z","relpermalink":"/post/first-contact/first-contact/","section":"post","summary":"A blog post describing the first steps of data cleaning and analysis using R.","tags":["R","Stata"],"title":"First contact with the data on R","type":"post"},{"authors":null,"categories":null,"content":" Before going into the details about studying economics with R, it makes sense to explain why you should use R compared to Stata. Before I start, please note that I have been using Stata occasionally for about a year whereas I spend much more time on R so I may forget some features that Stata has and that I am not aware of. However, I believe that what I have made with Stata corresponds to most Master students’ experiences, e.g. data cleaning and treatment, data analysis, econometrics, etc.\nNow we can begin.\nReason 1: R is free\nThat may seem a false argument for some people, especially because in many universities, students have freely access to Stata. However, in my experience, I know that we frequently want to work home or in group on some projects and therefore we need Stata on our personal laptop. Therefore, some cracked versions circulate between students and it is well-known that when downloading illegally softwares (and movies, TV shows, etc.), there’s always a risk of being infected by a virus. I don’t know if this happens often or not, maybe you will never suffer from it, but it would be just stupid to have to suffer from a hacking just because the statistical software was not free. That’s the big advantage of R: it is completely free. Whatever your operating system, you can download base R and every package you want and it won’t cost any money.\nReason 2: R is open-source\nI have already heard one of my professor complaining about the fact that Stata is a “black box” (not like those in planes but more like an opaque system). On the contrary, R is open-source (meaning that anyone can see the code, contribute to it and distribute it) and the code behind the functions you use is easily visible with just one click. That accessiblity entails the next argument, which is the diversity of packages.\nReason 3: the diversity of packages\nThere is A LOT of packages on R (more than 10,000 on CRAN as shown here, and it was in 2017!). Additionally to the packages on CRAN (the Comprehensive R Archive Network, where the stable versions of the packages are), some packages are hosted only on Github and others are made by users or companies only for private purposes and will not be released on open-source. The packages are the strength of R. Base-R (i.e. the basic version of R, without any packages manually installed) is a great start to learn how to code and to manipulate data, and in fact you can stay with base-R only if you limit your study to some basic data analysis. However, base-R may also be hard to learn and not very esthetic. Moreover, some packages allow to extend R functionalities beyond base-R.\nThis is a list (far from being exhaustive) of some of the most important packages for students in economics:\n tidyverse: this is a portmanteau word of tidy and universe. It regroups more than 20 packages for data import (readr), data treatment (dplyr, tidyr…), graphics (ggplot2), etc.\n rmarkdown: as a student (in economics but in other domains too), you will have to write a Master’s thesis and before that, you will certainly have to do some group projects, sort of small reports. When the data analysis will be done, you will have to write your report and to incorporate the results in the document. That can lead to some mistakes/typos that can lead to big errors, like changes in p-values between the results obtained in the statistical software and the word processing program (whether it is LaTeX or Microsoft Word). To guarantee that you won’t make this sort of mistakes, the most effective way is to write directly in R and to incorporate your code directly in the text. Therefore, in one document, you will have the text of your report and the code needed for the data analysis, all of that ready to be converted in PDF, HTML or Word.\n shiny: while rmarkdown promotes reproducibility by keeping all in a unique document, shiny goes a step further. Once you have made some data analysis, you can put it in a Shiny application (“app”) that will create a web page in which people interested in your work will be able to reproduce your results but also to check wether they are robust. Indeed, Shiny makes results reactive, meaning that you can change the sample size or the years or anything else you want and the results will automatically adapt. That is very useful in econometrics, where robustness is very important and always checked. There exist thousands and thousands of R packages which cover a large spectrum of the problems and questions you might have, and that is definitely a strength of R.\n  Reason 4: the community\nIt is certain that will have some problems with your code, everybody has. The documentation is very complete and allows to solve most of them, but sometimes you may need to seek for help online. It is quite probable that the question you ask yourself has already been asked by somebody else before you and if it has, you will find the answer on StackOverflow or on the RStudio Community.\nReason 5: RStudio is just a pleasure to use\nRStudio is the most used IDE for R (Integrated Desktop Environment, not the language but a software that permits to use more easily the language). It has tons of shortcuts and is very customizable. It is a real pleasure to use, and it can be linked to other great services like GitHub (maybe you don’t know what it is so in a few words, it is a service that permits version control i.e. keep a trace of every change in a project, whether it is a report, a package or a web application).\n","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"8bb9db17b3368f9f8737fb04d4636846","permalink":"/post/why-moving/why-moving/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/post/why-moving/why-moving/","section":"post","summary":"Some reasons that explain why I prefer R to Stata.","tags":["R","Stata"],"title":"Why you should move from Stata to R","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3960dd3bdc6f629fb800d1d2aaa7224f","permalink":"/resume/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/resume/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"Resume","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"65de3680a280f6bf29dc34fe1adad5a6","permalink":"/talks/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"Upcoming and recent talks / workshops","tags":null,"title":"Talks \u0026 Workshops","type":"widget_page"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"/license/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"}]